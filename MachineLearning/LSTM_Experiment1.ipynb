{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows importing Jupyter notebooks as modules\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import JupyterNotebookImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM\n",
    "import keras.backend as kb\n",
    "import keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from keras import regularizers, optimizers, initializers\n",
    "from numpy.random import seed\n",
    "import AlgoPlotting as plt\n",
    "#from AlgoPlotting import XYChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_it(X):\n",
    "    return np.expand_dims(X.reshape((-1,1)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate data\n",
    "# data = np.random.randint(-5,5,200)\n",
    "\n",
    "# n_data = len(data)\n",
    "# data = np.matrix(data)\n",
    "# n_train = int(0.8*n_data)\n",
    "\n",
    "# index_delay = 5\n",
    "# y_train = shape_it(data[:,:n_train])\n",
    "# x_train = shape_it(data[:,index_delay:(n_train+index_delay)])\n",
    "# y_test = shape_it(data[:,n_train:-index_delay])\n",
    "# x_test = shape_it(data[:,(n_train+index_delay):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    \n",
    "    #data = np.random.randint(-1,2,200)\n",
    "    #data = 2*(np.random.rand(200) - 0.5)\n",
    "    #data = np.cumsum(data)\n",
    "    #x = data\n",
    "    #y = [data[ii]+data[ii+1]*data[ii+2] for ii in range(200)]\n",
    "    \n",
    "    n = np.random.randint(5,15)\n",
    "    \n",
    "    x = []\n",
    "    for ii in range(n):\n",
    "        if 1 or np.random.rand() > 0.01 + 0.99 * ii/200:\n",
    "            x.append(-1)\n",
    "        else:\n",
    "            x.append(1)\n",
    "    \n",
    "    y = x[1:]\n",
    "    x = x[0:-1]\n",
    "        \n",
    "#     print(x)\n",
    "#     print(y)\n",
    "#     print(np.shape(x))\n",
    "#     print(np.shape(y))\n",
    "    \n",
    "    x = shape_it(np.array(x))\n",
    "    y = shape_it(np.array(y))\n",
    "    return x, y\n",
    "    \n",
    "#generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training data\n",
    "# training_chart = plt.XYChart(y=[x_train, y_train],\n",
    "#                              names=['X Train','Y Train'],\n",
    "#                              title='Training Data'\n",
    "#                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot testing data\n",
    "# testing_chart = plt.XYChart(y=[x_test, y_test],\n",
    "#                             names=['X Test','Y Test'],\n",
    "#                             title='Testing Data'\n",
    "#                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDLearningRateTracker(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        opt = self.model.optimizer\n",
    "        \n",
    "        # Not sure why but eval'ing 1 by 1 then calculating doesn't crash, but 1 line does\n",
    "        lr = kb.eval(opt.lr)\n",
    "        decay = kb.eval(opt.decay)\n",
    "        iterations = kb.eval(opt.iterations)\n",
    "        #lr = kb.eval(opt.lr * (1. / (1. + opt.decay * opt.iterations))) # This crashes\n",
    "        lr = (lr * (1. / (1. + decay * iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        logs['lr_calc'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternPredictingNetwork:\n",
    "    def __init__(self, model_dict, x_train, y_train, x_test, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        batch_size = 1\n",
    "        los = 'mse'\n",
    "        act = 'linear'\n",
    "        learning_rate = 0.00001*5\n",
    "        decay_rate = 0.00001\n",
    "        momentum = 0.0\n",
    "        sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "        opt = sgd\n",
    "        kreg = regularizers.l2(0.0001)\n",
    "        areg = regularizers.l1(0.0001)\n",
    "        #neurons = 300 # Works for delay = 5, SimpleRNN\n",
    "        neurons = 1\n",
    "        #batch_input_shape=(batch_size, self.x_train.shape[1], self.x_train.shape[2])\n",
    "        batch_input_shape=(batch_size, 1, 1)\n",
    "        use_regularization = False\n",
    "\n",
    "        if use_regularization:\n",
    "            self.model.add(SimpleRNN(neurons, batch_input_shape=batch_input_shape, stateful=True, return_sequences=True,\n",
    "                            kernel_regularizer=kreg, activity_regularizer=areg))\n",
    "            self.model.add(SimpleRNN(neurons, batch_input_shape=batch_input_shape, stateful=True, return_sequences=True,\n",
    "                            kernel_regularizer=kreg, activity_regularizer=areg))\n",
    "            self.model.add(SimpleRNN(neurons, batch_input_shape=batch_input_shape, stateful=True,\n",
    "                            kernel_regularizer=kreg, activity_regularizer=areg))\n",
    "            self.model.add(Dense(neurons, kernel_regularizer=kreg, activity_regularizer=areg, activation=act))\n",
    "            self.model.add(Dense(1, kernel_regularizer=kreg, activity_regularizer=areg))\n",
    "            self.model.compile(loss=los, optimizer=opt)\n",
    "        else:\n",
    "            #self.model.add(SimpleRNN(neurons, batch_input_shape=batch_input_shape, stateful=True, return_sequences=True))\n",
    "            #self.model.add(SimpleRNN(neurons, batch_input_shape=batch_input_shape, stateful=True, return_sequences=True))\n",
    "            self.model.add(SimpleRNN(neurons, activation=act, batch_input_shape=batch_input_shape, stateful=True, use_bias=False))\n",
    "            #self.model.add(Dense(neurons, activation=act))\n",
    "            #self.model.add(Dense(1))\n",
    "            self.model.compile(loss=los, optimizer=opt)\n",
    "        \n",
    "    def train_and_monitor(self, epochs=100, epoch_update_interval=10, losses_trim=0, losses_window=None):\n",
    "        predictions = []\n",
    "        losses = []\n",
    "        learning_rates = []\n",
    "        batch_size = 1\n",
    "\n",
    "        predictions_chart = plt.XYChart(title='Predictions', x_label='Index', y_label='Y', names=['Prediction', 'Test Data'])\n",
    "        losses_chart = plt.XYChart(title='Losses', x_label='Epochs', y_label='Loss')\n",
    "        dlosses_chart = plt.XYChart(title='Diff(Losses)', x_label='Epochs', y_label='Diff(Loss)')\n",
    "        lr_chart = plt.XYChart(title='Learning Rate', x_label='Epochs', y_label='Learning Rate')\n",
    "        \n",
    "        once = True\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.x_train, self.y_train = generate_data()\n",
    "            #self.x_test, self.y_test = generate_data()\n",
    "            self.x_test = self.x_train\n",
    "            self.y_test = self.y_train\n",
    "            \n",
    "            if once:\n",
    "                y_bad = np.reshape(self.y_train,(-1,))\n",
    "                print(y_bad)\n",
    "                print(y_bad.shape)\n",
    "                once = False\n",
    "            #self.model.predict(shape_it(np.array(-1)), batch_size=batch_size)\n",
    "            history = self.model.fit(self.x_train, np.reshape(self.y_train,(-1,)), epochs=1,\n",
    "                                     batch_size=batch_size, verbose=0, shuffle=False, callbacks=[SGDLearningRateTracker()])\n",
    "#             history = self.model.fit(self.x_train, self.y_train, epochs=1,\n",
    "#                                      batch_size=batch_size, verbose=0, shuffle=False, callbacks=[SGDLearningRateTracker()])\n",
    "            loss = history.history['loss'][0]\n",
    "            lr = history.history['lr_calc'][0]\n",
    "            losses.append(loss)\n",
    "            learning_rates.append(lr)\n",
    "\n",
    "            # Update the plots\n",
    "            if not epoch % epoch_update_interval:\n",
    "                self.model.reset_states()\n",
    "                predictions = []\n",
    "                for ii in range(len(self.x_test)):\n",
    "                    # make one-step forecast\n",
    "                    X = self.x_test[ii]\n",
    "                    X = X.reshape(1, 1, 1)\n",
    "                    y_pred = self.model.predict(X, batch_size=batch_size)[0,0]\n",
    "\n",
    "                    # store forecast\n",
    "                    predictions.append(y_pred)\n",
    "                    expected = self.y_test[ii]\n",
    "\n",
    "                # Push off the starting indices once the losses is long enough\n",
    "                if losses_window is not None:\n",
    "                    if len(losses) <= losses_window:\n",
    "                            y_losses = losses\n",
    "                            x_losses = np.arange(len(y_losses))\n",
    "                    else:\n",
    "                        start = len(losses) - losses_window\n",
    "                        y_losses = losses[start:]\n",
    "                        x_losses = np.arange(start, len(losses))\n",
    "                else:\n",
    "                    if len(losses) <= losses_trim:\n",
    "                        y_losses = losses\n",
    "                        x_losses = np.arange(len(y_losses))\n",
    "                    elif len(losses) > losses_trim and len(losses) < 2*losses_trim:\n",
    "                        start = len(losses) - losses_trim\n",
    "                        y_losses = losses[start:]\n",
    "                        x_losses = np.arange(start, len(losses))\n",
    "                    else:\n",
    "                        y_losses = losses[losses_trim:]\n",
    "                        x_losses = np.arange(losses_trim, len(losses))\n",
    "\n",
    "                predictions_chart.update(y=[predictions, self.y_test])\n",
    "                losses_chart.update(x=x_losses, y=y_losses)\n",
    "                dlosses_chart.update(x=x_losses[:-1], y=np.diff(y_losses))\n",
    "                lr_chart.update(y=learning_rates)\n",
    "            self.model.reset_states()\n",
    "    \n",
    "    # Forecast with updates each step\n",
    "    def one_step_forecast(self):\n",
    "        batch_size = 1\n",
    "        # One step forecast on testing data\n",
    "        self.model.reset_states()\n",
    "        self.model.predict(self.x_train, batch_size=batch_size)\n",
    "        predictions = []\n",
    "        for ii in range(len(self.x_test)):\n",
    "            # make one-step forecast\n",
    "            X = self.x_test[ii]\n",
    "            X = X.reshape(1, 1, 1)\n",
    "            yhat = self.model.predict(X, batch_size=batch_size)[0,0]\n",
    "\n",
    "            # store forecast\n",
    "            predictions.append(yhat)\n",
    "            expected = self.y_test[ii]\n",
    "            print('Index=%d, Predicted=%f, Expected=%f' % (ii, yhat, expected))\n",
    "\n",
    "        # report performance\n",
    "        rmse = np.sqrt(mean_squared_error(self.y_test.reshape(len(self.y_test)), predictions))\n",
    "        print('Test RMSE: %.3f' % rmse)\n",
    "        xy_chart = plt.XYChart(y=[predictions, self.y_test], names=['Prediction', 'Test Data'], title='One Step Prediction')\n",
    "        \n",
    "    def dynamic_forecast(self):\n",
    "        batch_size = 1\n",
    "        # Dynamic forecast on test data\n",
    "        self.model.reset_states()\n",
    "        self.model.predict(self.x_train, batch_size=batch_size)\n",
    "\n",
    "        dynpredictions = list()\n",
    "        dyhat = self.x_test[0]\n",
    "\n",
    "\n",
    "        for ii in range(len(self.x_test)):\n",
    "            # make one-step forecast\n",
    "            dyhat = yhat.reshape(1, 1, 1)\n",
    "            dyhat = model.predict(dyhat, batch_size=batch_size)[0,0]\n",
    "\n",
    "            # store forecast\n",
    "            dynpredictions.append(dyhat)\n",
    "            expected = self.y_test[ii]\n",
    "            print('Index=%d, Predicted Dynamically=%f, Expected=%f' % (ii, dyhat, expected))\n",
    "\n",
    "\n",
    "        drmse = np.sqrt(mean_squared_error(Y_test.reshape(len(self.y_test)), dynpredictions))\n",
    "        print('Test Dynamic RMSE: %.3f' % drmse)\n",
    "        xy_chart = plt.XYChart(y=[dynpredictions, self.y_test], names=['Dynamic Prediction', 'Test Data'], title='Dynamic Prediction')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model_dict = {}\n",
    "# epochs = 1000\n",
    "# epoch_update_interval = 10\n",
    "# #pattern_predicting_network = PatternPredictingNetwork(model_dict, x_train, y_train, x_test, y_test)\n",
    "# pattern_predicting_network = PatternPredictingNetwork(model_dict, np.array(0), np.array(0), np.array(0), np.array(0))\n",
    "# pattern_predicting_network.model.layers[0].set_weights(\n",
    "#     #[np.array([[1.048831]]), np.array([[-0.05480201]])]\n",
    "#     [np.array([[0.95]]), np.array([[0]])]\n",
    "# )\n",
    "# pattern_predicting_network.model.reset_states()\n",
    "# pattern_predicting_network.model.predict(shape_it(np.array(-1)), batch_size=1)\n",
    "pattern_predicting_network.train_and_monitor(epochs=epochs, epoch_update_interval=epoch_update_interval, losses_window=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pattern_predicting_network.model.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pattern_predicting_network.one_step_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pattern_predicting_network.model.layers[0].get_weights()\n",
    "weights = [weights[0][0][0], weights[1][0][0], weights[2][0]]\n",
    "\n",
    "print(weights)\n",
    "#(-0.75-weights[2])*weights[1]+(-1)*weights[0]+weights[2]\n",
    "\n",
    "(-1)*(weights[0]) + weights[2] + (-0.75)*(weights[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
