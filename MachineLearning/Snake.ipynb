{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import add\n",
    "\n",
    "\n",
    "class DQNAgent(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reward = 0\n",
    "        self.gamma = 0.9\n",
    "        self.dataframe = pd.DataFrame()\n",
    "        self.agent_target = 1\n",
    "        self.agent_predict = 0\n",
    "        self.learning_rate = 0.0005\n",
    "        self.model = self.network()\n",
    "        #self.model = self.network(\"weights.hdf5\")\n",
    "        self.epsilon = 0\n",
    "        self.actual = []\n",
    "        self.memory = []\n",
    "        self.short_memory = []\n",
    "\n",
    "    def get_state(self, game, player, food):\n",
    "\n",
    "        state = [\n",
    "            (player.x_change == 20 and player.y_change == 0 and ((list(map(add, player.position[-1], [20, 0])) in player.position) or\n",
    "            player.position[-1][0] + 20 >= (game.game_width - 20))) or (player.x_change == -20 and player.y_change == 0 and ((list(map(add, player.position[-1], [-20, 0])) in player.position) or\n",
    "            player.position[-1][0] - 20 < 20)) or (player.x_change == 0 and player.y_change == -20 and ((list(map(add, player.position[-1], [0, -20])) in player.position) or\n",
    "            player.position[-1][-1] - 20 < 20)) or (player.x_change == 0 and player.y_change == 20 and ((list(map(add, player.position[-1], [0, 20])) in player.position) or\n",
    "            player.position[-1][-1] + 20 >= (game.game_height-20))),  # danger straight\n",
    "\n",
    "            (player.x_change == 0 and player.y_change == -20 and ((list(map(add,player.position[-1],[20, 0])) in player.position) or\n",
    "            player.position[ -1][0] + 20 > (game.game_width-20))) or (player.x_change == 0 and player.y_change == 20 and ((list(map(add,player.position[-1],\n",
    "            [-20,0])) in player.position) or player.position[-1][0] - 20 < 20)) or (player.x_change == -20 and player.y_change == 0 and ((list(map(\n",
    "            add,player.position[-1],[0,-20])) in player.position) or player.position[-1][-1] - 20 < 20)) or (player.x_change == 20 and player.y_change == 0 and (\n",
    "            (list(map(add,player.position[-1],[0,20])) in player.position) or player.position[-1][\n",
    "             -1] + 20 >= (game.game_height-20))),  # danger right\n",
    "\n",
    "             (player.x_change == 0 and player.y_change == 20 and ((list(map(add,player.position[-1],[20,0])) in player.position) or\n",
    "             player.position[-1][0] + 20 > (game.game_width-20))) or (player.x_change == 0 and player.y_change == -20 and ((list(map(\n",
    "             add, player.position[-1],[-20,0])) in player.position) or player.position[-1][0] - 20 < 20)) or (player.x_change == 20 and player.y_change == 0 and (\n",
    "            (list(map(add,player.position[-1],[0,-20])) in player.position) or player.position[-1][-1] - 20 < 20)) or (\n",
    "            player.x_change == -20 and player.y_change == 0 and ((list(map(add,player.position[-1],[0,20])) in player.position) or\n",
    "            player.position[-1][-1] + 20 >= (game.game_height-20))), #danger left\n",
    "\n",
    "\n",
    "            player.x_change == -20,  # move left\n",
    "            player.x_change == 20,  # move right\n",
    "            player.y_change == -20,  # move up\n",
    "            player.y_change == 20,  # move down\n",
    "            food.x_food < player.x,  # food left\n",
    "            food.x_food > player.x,  # food right\n",
    "            food.y_food < player.y,  # food up\n",
    "            food.y_food > player.y  # food down\n",
    "            ]\n",
    "\n",
    "        for i in range(len(state)):\n",
    "            if state[i]:\n",
    "                state[i]=1\n",
    "            else:\n",
    "                state[i]=0\n",
    "\n",
    "        return np.asarray(state)\n",
    "\n",
    "    def set_reward(self, player, crash):\n",
    "        self.reward = 0\n",
    "        if crash:\n",
    "            self.reward = -10\n",
    "            return self.reward\n",
    "        if player.eaten:\n",
    "            self.reward = 10\n",
    "        return self.reward\n",
    "\n",
    "    def network(self, weights=None):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(output_dim=120, activation='relu', input_dim=11))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(output_dim=120, activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(output_dim=120, activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(output_dim=3, activation='softmax'))\n",
    "        opt = Adam(self.learning_rate)\n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "        if weights:\n",
    "            model.load_weights(weights)\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        self.short_memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "#     def replay_new(self, memory):\n",
    "#         if len(memory) > 1000:\n",
    "#             minibatch = random.sample(memory, 1000)\n",
    "#         else:\n",
    "#             minibatch = memory\n",
    "#         for state, action, reward, next_state, done in minibatch:\n",
    "#             target = reward\n",
    "#             if not done:\n",
    "#                 target = reward + self.gamma * np.amax(self.model.predict(np.array([next_state]))[0])\n",
    "#             target_f = self.model.predict(np.array([state]))\n",
    "#             target_f[0][np.argmax(action)] = target\n",
    "#             self.model.fit(np.array([state]), target_f, epochs=1, verbose=0)\n",
    "            \n",
    "    def replay_new(self, memory):\n",
    "        if len(self.short_memory) > 1000:\n",
    "            minibatch_short = random.sample(self.short_memory, 1000)\n",
    "        else:\n",
    "            minibatch_short = self.short_memory\n",
    "        if len(memory) > 1000:\n",
    "            minibatch_long = random.sample(memory, 1000)\n",
    "        else:\n",
    "            minibatch_long = memory\n",
    "            \n",
    "        minibatch = minibatch_short + minibatch_long\n",
    "            \n",
    "        state_array = len(minibatch) * [None]\n",
    "        target_f_array = len(minibatch) * [None]   \n",
    "        index = 0\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(np.array([next_state]))[0])\n",
    "            print(\"wow\")\n",
    "            target_f = self.model.predict(np.array([state]))\n",
    "            print('Reward ', reward, ', Target ', target, ', Targetf ', target_f)\n",
    "            target_f[0][np.argmax(action)] = target\n",
    "            print('Reward ', reward, ', Target ', target, ', Targetf ', target_f)\n",
    "            \n",
    "            state_array[index] = np.asarray(state)\n",
    "            target_f_array[index] = target_f[0]\n",
    "            \n",
    "            index += 1\n",
    "        state_array = np.asarray(state_array)\n",
    "        target_f_array = np.asarray(target_f_array)\n",
    "        self.model.fit(state_array, target_f_array, epochs=1, verbose=0, batch_size = 10)\n",
    "        self.short_memory = []\n",
    "\n",
    "    def train_short_memory(self, state, action, reward, next_state, done):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward + self.gamma * np.amax(self.model.predict(next_state.reshape((1, 11)))[0])\n",
    "        target_f = self.model.predict(state.reshape((1, 11)))\n",
    "        target_f[0][np.argmax(action)] = target\n",
    "        self.model.fit(state.reshape((1, 11)), target_f, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pygame\n",
    "from random import randint\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set options to activate or deactivate the game view, and its speed\n",
    "display_option = False\n",
    "speed = 0\n",
    "pygame.font.init()\n",
    "\n",
    "\n",
    "class Game:\n",
    "\n",
    "    def __init__(self, game_width, game_height):\n",
    "        pygame.display.set_caption('SnakeGen')\n",
    "        self.game_width = game_width\n",
    "        self.game_height = game_height\n",
    "        self.gameDisplay = pygame.display.set_mode((game_width, game_height+60))\n",
    "        self.bg = pygame.image.load(\"img/background.png\")\n",
    "        self.crash = False\n",
    "        self.player = Player(self)\n",
    "        self.food = Food()\n",
    "        self.score = 0\n",
    "\n",
    "\n",
    "class Player(object):\n",
    "\n",
    "    def __init__(self, game):\n",
    "        x = 0.45 * game.game_width\n",
    "        y = 0.5 * game.game_height\n",
    "        self.x = x - x % 20\n",
    "        self.y = y - y % 20\n",
    "        self.position = []\n",
    "        self.position.append([self.x, self.y])\n",
    "        self.food = 1\n",
    "        self.eaten = False\n",
    "        self.image = pygame.image.load('img/snakeBody.png')\n",
    "        self.x_change = 20\n",
    "        self.y_change = 0\n",
    "\n",
    "    def update_position(self, x, y):\n",
    "        if self.position[-1][0] != x or self.position[-1][1] != y:\n",
    "            if self.food > 1:\n",
    "                for i in range(0, self.food - 1):\n",
    "                    self.position[i][0], self.position[i][1] = self.position[i + 1]\n",
    "            self.position[-1][0] = x\n",
    "            self.position[-1][1] = y\n",
    "\n",
    "    def do_move(self, move, x, y, game, food,agent):\n",
    "        move_array = [self.x_change, self.y_change]\n",
    "\n",
    "        if self.eaten:\n",
    "\n",
    "            self.position.append([self.x, self.y])\n",
    "            self.eaten = False\n",
    "            self.food = self.food + 1\n",
    "        if np.array_equal(move ,[1, 0, 0]):\n",
    "            move_array = self.x_change, self.y_change\n",
    "        elif np.array_equal(move,[0, 1, 0]) and self.y_change == 0:  # right - going horizontal\n",
    "            move_array = [0, self.x_change]\n",
    "        elif np.array_equal(move,[0, 1, 0]) and self.x_change == 0:  # right - going vertical\n",
    "            move_array = [-self.y_change, 0]\n",
    "        elif np.array_equal(move, [0, 0, 1]) and self.y_change == 0:  # left - going horizontal\n",
    "            move_array = [0, -self.x_change]\n",
    "        elif np.array_equal(move,[0, 0, 1]) and self.x_change == 0:  # left - going vertical\n",
    "            move_array = [self.y_change, 0]\n",
    "        self.x_change, self.y_change = move_array\n",
    "        self.x = x + self.x_change\n",
    "        self.y = y + self.y_change\n",
    "\n",
    "        if self.x < 20 or self.x > game.game_width-40 or self.y < 20 or self.y > game.game_height-40 or [self.x, self.y] in self.position:\n",
    "            game.crash = True\n",
    "        eat(self, food, game)\n",
    "\n",
    "        self.update_position(self.x, self.y)\n",
    "\n",
    "    def display_player(self, x, y, food, game):\n",
    "        self.position[-1][0] = x\n",
    "        self.position[-1][1] = y\n",
    "\n",
    "        if game.crash == False:\n",
    "            for i in range(food):\n",
    "                x_temp, y_temp = self.position[len(self.position) - 1 - i]\n",
    "                game.gameDisplay.blit(self.image, (x_temp, y_temp))\n",
    "\n",
    "            update_screen()\n",
    "        else:\n",
    "            pygame.time.wait(300)\n",
    "\n",
    "\n",
    "class Food(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x_food = 240\n",
    "        self.y_food = 200\n",
    "        self.image = pygame.image.load('img/food2.png')\n",
    "\n",
    "    def food_coord(self, game, player):\n",
    "        x_rand = randint(20, game.game_width - 40)\n",
    "        self.x_food = x_rand - x_rand % 20\n",
    "        y_rand = randint(20, game.game_height - 40)\n",
    "        self.y_food = y_rand - y_rand % 20\n",
    "        if [self.x_food, self.y_food] not in player.position:\n",
    "            return self.x_food, self.y_food\n",
    "        else:\n",
    "            self.food_coord(game,player)\n",
    "\n",
    "    def display_food(self, x, y, game):\n",
    "        game.gameDisplay.blit(self.image, (x, y))\n",
    "        update_screen()\n",
    "\n",
    "\n",
    "def eat(player, food, game):\n",
    "    if player.x == food.x_food and player.y == food.y_food:\n",
    "        food.food_coord(game, player)\n",
    "        player.eaten = True\n",
    "        game.score = game.score + 1\n",
    "\n",
    "\n",
    "def get_record(score, record):\n",
    "        if score >= record:\n",
    "            return score\n",
    "        else:\n",
    "            return record\n",
    "\n",
    "\n",
    "def display_ui(game, score, record):\n",
    "    myfont = pygame.font.SysFont('Segoe UI', 20)\n",
    "    myfont_bold = pygame.font.SysFont('Segoe UI', 20, True)\n",
    "    text_score = myfont.render('SCORE: ', True, (0, 0, 0))\n",
    "    text_score_number = myfont.render(str(score), True, (0, 0, 0))\n",
    "    text_highest = myfont.render('HIGHEST SCORE: ', True, (0, 0, 0))\n",
    "    text_highest_number = myfont_bold.render(str(record), True, (0, 0, 0))\n",
    "    game.gameDisplay.blit(text_score, (45, 440))\n",
    "    game.gameDisplay.blit(text_score_number, (120, 440))\n",
    "    game.gameDisplay.blit(text_highest, (190, 440))\n",
    "    game.gameDisplay.blit(text_highest_number, (350, 440))\n",
    "    game.gameDisplay.blit(game.bg, (10, 10))\n",
    "\n",
    "\n",
    "def display(player, food, game, record):\n",
    "    game.gameDisplay.fill((255, 255, 255))\n",
    "    display_ui(game, game.score, record)\n",
    "    player.display_player(player.position[-1][0], player.position[-1][1], player.food, game)\n",
    "    food.display_food(food.x_food, food.y_food, game)\n",
    "\n",
    "\n",
    "def update_screen():\n",
    "    pygame.display.update()\n",
    "\n",
    "\n",
    "def initialize_game(player, game, food, agent):\n",
    "    state_init1 = agent.get_state(game, player, food)  # [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
    "    action = [1, 0, 0]\n",
    "    player.do_move(action, player.x, player.y, game, food, agent)\n",
    "    state_init2 = agent.get_state(game, player, food)\n",
    "    reward1 = agent.set_reward(player, game.crash)\n",
    "    agent.remember(state_init1, action, reward1, state_init2, game.crash)\n",
    "    agent.replay_new(agent.memory)\n",
    "\n",
    "\n",
    "def plot_seaborn(array_counter, array_score):\n",
    "    sns.set(color_codes=True)\n",
    "    ax = sns.regplot(np.array([array_counter])[0], np.array([array_score])[0], color=\"b\", x_jitter=.1, line_kws={'color':'green'})\n",
    "    ax.set(xlabel='games', ylabel='score')\n",
    "    plt.show()\n",
    "\n",
    "def run():\n",
    "    pygame.init()\n",
    "    agent = DQNAgent()\n",
    "    counter_games = 0\n",
    "    score_plot = []\n",
    "    counter_plot =[]\n",
    "    record = 0\n",
    "    while counter_games < 150:\n",
    "        # Initialize classes\n",
    "        game = Game(440, 440)\n",
    "        player1 = game.player\n",
    "        food1 = game.food\n",
    "\n",
    "        # Perform first move\n",
    "        initialize_game(player1, game, food1, agent)\n",
    "        if display_option:\n",
    "            display(player1, food1, game, record)\n",
    "\n",
    "        while not game.crash:\n",
    "            #agent.epsilon is set to give randomness to actions\n",
    "            agent.epsilon = 80 - counter_games\n",
    "            \n",
    "            #get old state\n",
    "            state_old = agent.get_state(game, player1, food1)\n",
    "            \n",
    "            #perform random actions based on agent.epsilon, or choose the action\n",
    "            if randint(0, 200) < agent.epsilon:\n",
    "                final_move = to_categorical(randint(0, 2), num_classes=3)\n",
    "            else:\n",
    "                # predict action based on the old state\n",
    "                prediction = agent.model.predict(state_old.reshape((1,11)))\n",
    "                final_move = to_categorical(np.argmax(prediction[0]), num_classes=3)\n",
    "                \n",
    "            #perform new move and get new state\n",
    "            player1.do_move(final_move, player1.x, player1.y, game, food1, agent)\n",
    "            state_new = agent.get_state(game, player1, food1)\n",
    "            \n",
    "            #set treward for the new state\n",
    "            reward = agent.set_reward(player1, game.crash)\n",
    "            \n",
    "            #train short memory base on the new action and state\n",
    "            #agent.train_short_memory(state_old, final_move, reward, state_new, game.crash)\n",
    "            \n",
    "            # store the new data into a long term memory\n",
    "            agent.remember(state_old, final_move, reward, state_new, game.crash)\n",
    "            record = get_record(game.score, record)\n",
    "            if display_option:\n",
    "                display(player1, food1, game, record)\n",
    "                pygame.time.wait(speed)\n",
    "        \n",
    "        agent.replay_new(agent.memory)\n",
    "        counter_games += 1\n",
    "        print('Game', counter_games, '      Score:', game.score)\n",
    "        score_plot.append(game.score)\n",
    "        counter_plot.append(counter_games)\n",
    "    agent.model.save_weights('weights.hdf5')\n",
    "    plot_seaborn(counter_plot, score_plot)\n",
    "\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
