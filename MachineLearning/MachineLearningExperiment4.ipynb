{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Experiment \\#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows importing Jupyter notebooks as modules\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import JupyterNotebookImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "# Plotly imports\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import ipywidgets\n",
    "\n",
    "from operator import add\n",
    "\n",
    "import bisect\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Keras imports\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "#from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding, SimpleRNN\n",
    "\n",
    "import AlgoPlotting as aplt\n",
    "import AlgoProcessing as aprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = r'''..\\Data\\IVE_bidaskvol1min.txt'''\n",
    "\n",
    "colnames = ['Date', 'Time', 'BidOpen', 'BidHigh', 'BidLow', 'BidClose', 'AskOpen', 'AskHigh', 'AskLow', 'AskClose', 'Volume']\n",
    "fullpricedata = pd.read_csv(datafile, names=colnames)\n",
    "\n",
    "fullpricedata['DateTime'] = (fullpricedata['Date']+fullpricedata['Time']).map(lambda x: datetime.datetime(int(x[6:10]), int(x[0:2]), int(x[3:5]), int(x[10:12]), int(x[13:15])))\n",
    "del fullpricedata['Date']\n",
    "del fullpricedata['Time']\n",
    "\n",
    "fullpricedata = fullpricedata[[(dt >= datetime.datetime(dt.year, dt.month, dt. day, 9, 30, 0)) and (dt <= datetime.datetime(dt.year, dt.month, dt. day, 16, 0, 0)) for dt in fullpricedata['DateTime']]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricedata = fullpricedata[fullpricedata['DateTime'] > datetime.datetime(2018,6,1,0,0,0)].copy()\n",
    "#pricedata = pricedata[pricedata['DateTime'] < datetime.datetime(2019,1,3,0,0,0)].copy()\n",
    "pricedata = pricedata.reset_index()\n",
    "del pricedata['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddIndicatorRSI(timeframe, periods=14):\n",
    "    diffdata = np.diff(pricedata['BidClose'])\n",
    "    diffdata = np.insert(diffdata,0,0)\n",
    "    RSI = len(pricedata) * [None]\n",
    "    \n",
    "    index = 0\n",
    "    period = 0\n",
    "    gains = 0\n",
    "    losses = 0\n",
    "    while index < len(pricedata):\n",
    "        if period < periods:\n",
    "            period_weight = 1.0/(period+1.0)\n",
    "        else:\n",
    "            period_weight = 1.0/periods\n",
    "            \n",
    "        period_change = 0\n",
    "        starttime = pricedata['DateTime'][index]\n",
    "        while True:\n",
    "            if index == len(pricedata):\n",
    "                break\n",
    "            if pricedata['DateTime'][index] - starttime >= datetime.timedelta(minutes=timeframe):\n",
    "                break\n",
    "            \n",
    "            period_change += diffdata[index]\n",
    "            if period_change > 0:\n",
    "                RS_gains = period_change * period_weight + gains * (1.0 - period_weight)\n",
    "                RS_losses = 0 * period_weight + losses * (1.0 - period_weight)\n",
    "            else:\n",
    "                RS_gains = 0 * period_weight + gains * (1.0 - period_weight)\n",
    "                RS_losses = - period_change * period_weight + losses * (1.0 - period_weight)\n",
    "                \n",
    "            if RS_losses == 0:\n",
    "                RSI[index] = 1.0\n",
    "            else:\n",
    "                # Yes, the 2.0 is wrong, but I assume it's best to have NN inputs averaging zero?\n",
    "                RSI[index] = 1.0 - 2.0/(1.0 + RS_gains/RS_losses)\n",
    "            \n",
    "            index += 1\n",
    "            \n",
    "        if period_change > 0:\n",
    "            gains = period_change * period_weight + gains * (1.0 - period_weight)\n",
    "            losses = 0 * period_weight + losses * (1.0 - period_weight)\n",
    "        else:\n",
    "            gains = 0 * period_weight + gains * (1.0 - period_weight)\n",
    "            losses = - period_change * period_weight + losses * (1.0 - period_weight)\n",
    "            \n",
    "        period += 1\n",
    "        \n",
    "    pricedata['Rsi' + str(timeframe)] = RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of a bastardized version of On-Balance Volume...\n",
    "def AddIndicatorOBV(periods=14, averaging=100):\n",
    "    diffdata = np.diff(pricedata['BidClose'])\n",
    "    diffdata = np.insert(diffdata,0,0)\n",
    "    OBV = len(pricedata) * [None]\n",
    "    \n",
    "    avg_vol = 0\n",
    "    obv = 0\n",
    "    index = 0\n",
    "    while index < len(pricedata):\n",
    "        if index < periods:\n",
    "            period_weight = 1.0/(index+1.0)\n",
    "        else:\n",
    "            period_weight = 1.0/periods\n",
    "        \n",
    "        if index < averaging:\n",
    "            averaging_weight = 1.0/(index+1.0)\n",
    "        else:\n",
    "            averaging_weight = 1.0/averaging\n",
    "            \n",
    "        period_vol = pricedata['Volume'][index]\n",
    "        avg_vol = period_vol * averaging_weight + avg_vol * (1.0 - averaging_weight)\n",
    "            \n",
    "        period_change = diffdata[index]\n",
    "        if period_change > 0:\n",
    "            OBV[index] = period_vol / avg_vol * period_weight + obv * (1.0 - period_weight)\n",
    "        elif period_change < 0:\n",
    "            OBV[index] = - period_vol / avg_vol * period_weight + obv * (1.0 - period_weight)\n",
    "        else:\n",
    "            OBV[index] = obv * (1.0 - period_weight)\n",
    "        \n",
    "        OBV[index] = 3.0/(1.0 + np.exp(-OBV[index]))-1.5\n",
    "        obv = OBV[index]\n",
    "        index += 1\n",
    "            \n",
    "    pricedata['Obv' + str(periods)] = OBV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of a bastardized version of On-Balance Volume...\n",
    "def AddIndicatorDiff():\n",
    "    diffdata = np.diff(pricedata['BidClose'])\n",
    "    diffdata = np.insert(diffdata,0,0)\n",
    "            \n",
    "    pricedata['DiffPrice'] = diffdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AddIndicatorRSI(1)\n",
    "AddIndicatorRSI(5)\n",
    "AddIndicatorRSI(30)\n",
    "AddIndicatorOBV(14)\n",
    "AddIndicatorDiff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricedata\n",
    "xy_chart = aplt.XYChart(y=[pricedata['Volume']/10000, pricedata['Obv14']],\n",
    "                       names = ['Volume', 'OBV14', 'Diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that returns a tuple containing numpy arrays of NN inputs and rewards from the specified date range\n",
    "def get_inputs_and_rewards(start_date, end_date, pricedata):\n",
    "    inputs = []\n",
    "    rewards = []\n",
    "    days = []\n",
    "    \n",
    "    #xy_chart = aplt.XYChart()\n",
    "    \n",
    "    # Get list of days\n",
    "    curr_day = start_date\n",
    "    while curr_day < end_date:\n",
    "        days.append(curr_day)\n",
    "        curr_day = curr_day + datetime.timedelta(days=1)\n",
    "\n",
    "    # Iterate over days and get inputs/rewards\n",
    "    for day in days:\n",
    "        daypricedata = pricedata[pricedata['DateTime'] > pd.Timestamp(day)].copy()\n",
    "        daypricedata = daypricedata[daypricedata['DateTime'] < pd.Timestamp(day) + datetime.timedelta(days=1)].copy()\n",
    "        daypricedata = daypricedata.reset_index()\n",
    "        N = 0#agent.inputs + 1\n",
    "        n = 10\n",
    "        M = len(daypricedata)-N-n\n",
    "        \n",
    "        stock_price = np.array(daypricedata['BidClose'])\n",
    "        day_rewards_raw = aprc.generate_prediction_data(daypricedata['BidClose'], sell_target_diff=0.2, stop_loss_diff=0.2)\n",
    "        if day_rewards_raw.shape[0] > 0:\n",
    "            day_rewards = aprc.filter_prediction_data(day_rewards_raw, tol=3)\n",
    "            min_val = np.min(stock_price)\n",
    "            max_val = np.max(stock_price)\n",
    "            #xy_chart.update(y=[stock_price - min_val, (max_val - min_val)*day_rewards_raw, (max_val - min_val)*day_rewards], names=['stock_price', 'day_rewards_raw', 'day_rewards'])\n",
    "\n",
    "        for index in range(0,M):\n",
    "            inputs.append(np.array([daypricedata['Rsi1'][index],\n",
    "                                    daypricedata['Rsi5'][index],\n",
    "                                    daypricedata['Obv14'][index]]))\n",
    "            #rewards.append(daypricedata['BidClose'][index+N+n] - daypricedata['BidClose'][index+N])\n",
    "            rewards.append(day_rewards[index])\n",
    "            \n",
    "            \n",
    "    return (np.array(inputs), np.array(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_inputs_and_rewards(datetime.datetime(2019,1,1,0,0,0), datetime.datetime(2019,2,1,0,0,0), pricedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.inputs = 3\n",
    "        self.outputs = 1\n",
    "        self.batch_size = 30\n",
    "        self.model = self.network()\n",
    "        print(self.model.summary())\n",
    "            \n",
    "    def network(self, weights=None):\n",
    "        model = Sequential()\n",
    "        \n",
    "        num_layers = 3\n",
    "        neurons_per_layer = 20\n",
    "        dropout = 0.0\n",
    "        reg = 0.00000\n",
    "        act = 'tanh'\n",
    "        output_act = 'sigmoid'\n",
    "        learning_rate = 0.0002\n",
    "        decay_rate = 0.0005\n",
    "        opt = optimizers.Adam(lr=learning_rate, decay=decay_rate)\n",
    "        \n",
    "        if num_layers == 0:\n",
    "            if dropout > 0:\n",
    "                    model.add(Dropout(dropout))\n",
    "            model.add(Dense(units=self.outputs, activation=output_act, input_dim=self.inputs,\n",
    "                        kernel_regularizer=regularizers.l2(reg),\n",
    "                        activity_regularizer=regularizers.l2(reg)))\n",
    "        else:\n",
    "            model.add(Dense(units=neurons_per_layer, activation=act, input_dim=self.inputs,\n",
    "                            kernel_regularizer=regularizers.l2(reg),\n",
    "                            activity_regularizer=regularizers.l2(reg)))\n",
    "            \n",
    "            for ii in range(num_layers - 1):\n",
    "                if dropout > 0:\n",
    "                    model.add(Dropout(dropout))\n",
    "                model.add(Dense(units=neurons_per_layer, activation=act,\n",
    "                                kernel_regularizer=regularizers.l2(reg),\n",
    "                                activity_regularizer=regularizers.l2(reg)))\n",
    "                \n",
    "            if dropout > 0:\n",
    "                    model.add(Dropout(dropout))\n",
    "            model.add(Dense(units=self.outputs, activation=output_act,\n",
    "                            kernel_regularizer=regularizers.l2(reg),\n",
    "                            activity_regularizer=regularizers.l2(reg)))\n",
    "    \n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "#         model = Sequential()\n",
    "#         batch_input_shape = (self.batch_size,self.inputs,1)\n",
    "#         los = 'binary_crossentropy' # 'mse'\n",
    "#         act = 'tanh'\n",
    "#         learning_rate = 0.00005*1000\n",
    "#         decay_rate = learning_rate/1000\n",
    "#         momentum = 0.0\n",
    "#         sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "#         opt = sgd\n",
    "#         kreg = None # regularizers.l2(0.0005)\n",
    "#         areg = None # regularizers.l2(0.0005)\n",
    "#         neurons = 3\n",
    "#         num_recurrent_layers = 3\n",
    "#         for _ in range(max(num_recurrent_layers - 1, 0)):\n",
    "#             model.add(SimpleRNN(neurons, activation=act, batch_input_shape=batch_input_shape, stateful=True, return_sequences=True,\n",
    "#                                      kernel_regularizer=kreg, activity_regularizer=areg))\n",
    "#         model.add(SimpleRNN(neurons, activation=act, batch_input_shape=batch_input_shape, stateful=True,\n",
    "#                                  kernel_regularizer=kreg, activity_regularizer=areg))\n",
    "#         model.add(Dense(neurons, activation=act, \n",
    "#                              kernel_regularizer=kreg, activity_regularizer=areg))\n",
    "#         model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#         model.compile(loss=los, optimizer=opt)\n",
    "\n",
    "        return model    \n",
    "\n",
    "    # Train the NN    \n",
    "    def train(self, inputs, outputs, epochs):\n",
    "        return self.model.fit(inputs, outputs, epochs=epochs, verbose=0, batch_size=self.batch_size)\n",
    "    \n",
    "    # Train and evaluate at intervals on test data to see if the losses on test data are decreasing\n",
    "    def train_and_evaluate(self, x_train, y_train, x_test, y_test, epochs, epoch_eval_interval):\n",
    "        train_len = x_train.shape[0] - x_train.shape[0]%self.batch_size\n",
    "        test_len = x_test.shape[0] - x_test.shape[0]%self.batch_size\n",
    "        \n",
    "        x_train = x_train[:train_len]\n",
    "        y_train = y_train[:train_len]\n",
    "        x_test = x_test[:test_len]\n",
    "        y_test = y_test[:test_len]\n",
    "        \n",
    "        intervals = int(np.ceil(epochs/epoch_eval_interval))\n",
    "        testing_losses = []\n",
    "        testing_losses_idx = []\n",
    "        training_losses = []\n",
    "        \n",
    "        # Initialize charts\n",
    "        input_chart = aplt.XYChart(title='Input', x_label='Index', y_label='X', names=['Test Input ' + str(ii) for ii in range(x_test.shape[1])])\n",
    "        predictions_chart = aplt.XYChart(title='Predictions', x_label='Index', y_label='Y', names=['Prediction', 'Test Data'])\n",
    "        losses_chart = aplt.XYChart(title='Losses', x_label='Epochs', y_label='Loss')\n",
    "        \n",
    "        # Reshape\n",
    "#         s = x_test.shape\n",
    "#         x_test = x_test.reshape(s[0], s[1], 1)\n",
    "#         s = x_train.shape\n",
    "#         x_train = x_train.reshape(s[0], s[1], 1)\n",
    "        \n",
    "        # Train in intervals of epochs so we can evaluate the NN performance on testing data in between\n",
    "        for ii in range(intervals):\n",
    "            history = self.train(x_train, y_train, epochs=epoch_eval_interval)\n",
    "            interval_training_losses = history.history['loss']\n",
    "            self.model.reset_states()\n",
    "            \n",
    "            training_losses = training_losses + interval_training_losses\n",
    "            training_predictions = self.model.predict(x_train, verbose=0, batch_size=self.batch_size)\n",
    "            self.model.reset_states()\n",
    "            \n",
    "            interval_testing_loss = self.model.evaluate(x_test, y_test, verbose=0, batch_size=self.batch_size)\n",
    "            self.model.reset_states()\n",
    "            predictions = self.model.predict(x_test, verbose=0, batch_size=self.batch_size)\n",
    "            testing_losses.append(interval_testing_loss)\n",
    "            testing_losses_idx.append((ii+1)*epoch_eval_interval)\n",
    "            self.model.reset_states()\n",
    "\n",
    "            input_chart.update(y=[x_test[:,ii] for ii in range(x_test.shape[1])])\n",
    "            predictions_chart.update(y=[training_predictions, y_train])\n",
    "            losses_chart.update(y=[testing_losses, training_losses],\n",
    "                                x=[[epoch_eval_interval*ii for ii in range(len(testing_losses))], [ii for ii in range(len(training_losses))]],\n",
    "                                names=['Testing Losses', 'Training Losses'])\n",
    "        \n",
    "        # Convert to np.array\n",
    "        testing_losses = np.array(testing_losses)\n",
    "        testing_losses_idx = np.array(testing_losses_idx)\n",
    "        \n",
    "        return (training_losses, testing_losses, testing_losses_idx)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DQNAgent()\n",
    "\n",
    "# Indexs for training and testing ranges\n",
    "training_start_idx = 300\n",
    "training_end_idx = np.floor(len(pricedata)/2)\n",
    "testing_start_idx = training_end_idx + 1\n",
    "testing_end_idx = len(pricedata) -  1\n",
    "\n",
    "# Training date range\n",
    "training_start_date = pricedata['DateTime'][training_start_idx].date()\n",
    "training_end_date = pricedata['DateTime'][training_end_idx].date()\n",
    "\n",
    "# Testing date range\n",
    "testing_start_date = pricedata['DateTime'][testing_start_idx].date()\n",
    "testing_end_date = pricedata['DateTime'][testing_end_idx].date()\n",
    "\n",
    "# Training inputs and rewards\n",
    "(x_train, y_train) = get_inputs_and_rewards(start_date=training_start_date,\n",
    "                                                             end_date=training_end_date,\n",
    "                                                             pricedata=pricedata)\n",
    "# Testing inputs and rewards\n",
    "(x_test, y_test) = get_inputs_and_rewards(start_date=testing_start_date,\n",
    "                                                           end_date=testing_end_date,\n",
    "                                                           pricedata=pricedata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Amount of training time\n",
    "epochs = 10000\n",
    "epoch_eval_interval = 1\n",
    "\n",
    "# Train the NN\n",
    "(training_losses, testing_losses, testing_losses_idx) = agent.train_and_evaluate(x_train=x_train,\n",
    "                                                                                 y_train=y_train,\n",
    "                                                                                 x_test=x_test,\n",
    "                                                                                 y_test=y_test,\n",
    "                                                                                 epochs=epochs,\n",
    "                                                                                 epoch_eval_interval=epoch_eval_interval)\n",
    "\n",
    "# Get the performance on the training and testing data after training\n",
    "training_predictions = agent.model.predict_on_batch(x_train)\n",
    "testing_predictions = agent.model.predict_on_batch(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idx_plot = [ii for ii in range(len(training_predictions))]\n",
    "testing_idx_plot = [ii for ii in range(len(testing_predictions))]\n",
    "\n",
    "training_predictions_plot = [w[0] for w in training_predictions]\n",
    "testing_predictions_plot = [w[0] for w in testing_predictions]\n",
    "\n",
    "print('Mean Training Prediction: ', np.mean(training_predictions_plot))\n",
    "print('Mean Training Reward:     ', np.mean(training_rewards))\n",
    "print('Mean Testing Prediction:  ', np.mean(testing_predictions_plot))\n",
    "print('Mean Testing Reward:      ', np.mean(testing_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predictions_chart = PredictionsChart(testing_idx_plot, testing_rewards, testing_predictions_plot, title='Testing')\n",
    "testing_predictions_chart.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do List\n",
    "\n",
    "* Extract volume per minute data from tick data\n",
    "* LossesChart/etc. applied to separate test data\n",
    "* Try feeding a vector of indicators instead of raw price data\n",
    "* Implement actual buy/sell strategy based on NN output, evaluate performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
