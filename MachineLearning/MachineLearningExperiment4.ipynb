{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Experiment \\#1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "# Plotly imports\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "import ipywidgets\n",
    "\n",
    "from operator import add\n",
    "\n",
    "import bisect\n",
    "import datetime\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Keras imports\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "#from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = r'''..\\Data\\IVE_bidaskvol1min.txt'''\n",
    "\n",
    "colnames = ['Date', 'Time', 'BidOpen', 'BidHigh', 'BidLow', 'BidClose', 'AskOpen', 'AskHigh', 'AskLow', 'AskClose', 'Volume']\n",
    "fullpricedata = pd.read_csv(datafile, names=colnames)\n",
    "\n",
    "fullpricedata['DateTime'] = (fullpricedata['Date']+fullpricedata['Time']).map(lambda x: datetime.datetime(int(x[6:10]), int(x[0:2]), int(x[3:5]), int(x[10:12]), int(x[13:15])))\n",
    "del fullpricedata['Date']\n",
    "del fullpricedata['Time']\n",
    "\n",
    "fullpricedata = fullpricedata[[(dt >= datetime.datetime(dt.year, dt.month, dt. day, 9, 30, 0)) and (dt <= datetime.datetime(dt.year, dt.month, dt. day, 16, 0, 0)) for dt in fullpricedata['DateTime']]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricedata = fullpricedata[fullpricedata['DateTime'] > datetime.datetime(2019,1,1,0,0,0)].copy()\n",
    "#pricedata = pricedata[pricedata['DateTime'] < datetime.datetime(2019,1,3,0,0,0)].copy()\n",
    "pricedata = pricedata.reset_index()\n",
    "del pricedata['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddIndicatorRSI(timeframe, periods=14):\n",
    "    diffdata = np.diff(pricedata['BidClose'])\n",
    "    diffdata = np.insert(diffdata,0,0)\n",
    "    RSI = len(pricedata) * [None]\n",
    "    \n",
    "    index = 0\n",
    "    period = 0\n",
    "    gains = 0\n",
    "    losses = 0\n",
    "    while index < len(pricedata):\n",
    "        if period < periods:\n",
    "            period_weight = 1.0/(period+1.0)\n",
    "        else:\n",
    "            period_weight = 1.0/periods\n",
    "            \n",
    "        period_change = 0\n",
    "        starttime = pricedata['DateTime'][index]\n",
    "        while True:\n",
    "            if index == len(pricedata):\n",
    "                break\n",
    "            if pricedata['DateTime'][index] - starttime >= datetime.timedelta(minutes=timeframe):\n",
    "                break\n",
    "            \n",
    "            period_change += diffdata[index]\n",
    "            if period_change > 0:\n",
    "                RS_gains = period_change * period_weight + gains * (1.0 - period_weight)\n",
    "                RS_losses = 0 * period_weight + losses * (1.0 - period_weight)\n",
    "            else:\n",
    "                RS_gains = 0 * period_weight + gains * (1.0 - period_weight)\n",
    "                RS_losses = - period_change * period_weight + losses * (1.0 - period_weight)\n",
    "                \n",
    "            if RS_losses == 0:\n",
    "                RSI[index] = 1.0\n",
    "            else:\n",
    "                # Yes, the 2.0 is wrong, but I assume it's best to have NN inputs averaging zero?\n",
    "                RSI[index] = 1.0 - 2.0/(1.0 + RS_gains/RS_losses)\n",
    "            \n",
    "            index += 1\n",
    "            \n",
    "        if period_change > 0:\n",
    "            gains = period_change * period_weight + gains * (1.0 - period_weight)\n",
    "            losses = 0 * period_weight + losses * (1.0 - period_weight)\n",
    "        else:\n",
    "            gains = 0 * period_weight + gains * (1.0 - period_weight)\n",
    "            losses = - period_change * period_weight + losses * (1.0 - period_weight)\n",
    "            \n",
    "        period += 1\n",
    "        \n",
    "    pricedata['Rsi' + str(timeframe)] = RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of a bastardized version of On-Balance Volume...\n",
    "def AddIndicatorOBV(periods=14, averaging=100):\n",
    "    diffdata = np.diff(pricedata['BidClose'])\n",
    "    diffdata = np.insert(diffdata,0,0)\n",
    "    OBV = len(pricedata) * [None]\n",
    "    \n",
    "    avg_vol = 0\n",
    "    obv = 0\n",
    "    index = 0\n",
    "    while index < len(pricedata):\n",
    "        if index < periods:\n",
    "            period_weight = 1.0/(index+1.0)\n",
    "        else:\n",
    "            period_weight = 1.0/periods\n",
    "        \n",
    "        if index < averaging:\n",
    "            averaging_weight = 1.0/(index+1.0)\n",
    "        else:\n",
    "            averaging_weight = 1.0/averaging\n",
    "            \n",
    "        period_vol = pricedata['Volume'][index]\n",
    "        avg_vol = period_vol * averaging_weight + avg_vol * (1.0 - averaging_weight)\n",
    "            \n",
    "        period_change = diffdata[index]\n",
    "        if period_change > 0:\n",
    "            OBV[index] = period_vol / avg_vol * period_weight + obv * (1.0 - period_weight)\n",
    "        elif period_change < 0:\n",
    "            OBV[index] = - period_vol / avg_vol * period_weight + obv * (1.0 - period_weight)\n",
    "        else:\n",
    "            OBV[index] = obv * (1.0 - period_weight)\n",
    "        \n",
    "        OBV[index] = 3.0/(1.0 + np.exp(-OBV[index]))-1.5\n",
    "        index += 1\n",
    "            \n",
    "    pricedata['Obv' + str(periods)] = OBV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AddIndicatorRSI(1)\n",
    "AddIndicatorRSI(5)\n",
    "AddIndicatorRSI(30)\n",
    "AddIndicatorOBV(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that returns a tuple containing numpy arrays of NN inputs and rewards from the specified date range\n",
    "def get_inputs_and_rewards(start_date, end_date, pricedata):\n",
    "    inputs = []\n",
    "    rewards = []\n",
    "    days = []\n",
    "    \n",
    "    # Get list of days\n",
    "    curr_day = start_date\n",
    "    while curr_day < end_date:\n",
    "        days.append(curr_day)\n",
    "        curr_day = curr_day + datetime.timedelta(days=1)\n",
    "\n",
    "    # Iterate over days and get inputs/rewards\n",
    "    for day in days:\n",
    "        daypricedata = pricedata[pricedata['DateTime'] > pd.Timestamp(day)].copy()\n",
    "        daypricedata = daypricedata[daypricedata['DateTime'] < pd.Timestamp(day) + datetime.timedelta(days=1)].copy()\n",
    "        daypricedata = daypricedata.reset_index()\n",
    "        N = 0#agent.inputs + 1\n",
    "        n = 10\n",
    "        M = len(daypricedata)-N-n\n",
    "\n",
    "        for index in range(0,M):\n",
    "            #diffs = np.diff(daypricedata['BidClose'][index:index+N])\n",
    "            #vols = np.array(daypricedata['Volume'][index:index+N-1])\n",
    "            #inputs.append(np.concatenate((diffs, vols)))\n",
    "            #inputs.append(diffs)\n",
    "            inputs.append(np.array([daypricedata['Rsi1'][index], daypricedata['Rsi5'][index], daypricedata['Obv14'][index]]))\n",
    "            rewards.append(daypricedata['BidClose'][index+N+n] - daypricedata['BidClose'][index+N])\n",
    "            \n",
    "    return (np.array(inputs), np.array(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that returns a tuple containing numpy arrays of NN inputs and rewards from the specified date range\n",
    "def get_lstm_inputs_and_rewards(start_date, end_date, pricedata):\n",
    "    inputs = []\n",
    "    rewards = []\n",
    "    days = []\n",
    "    \n",
    "    # Get list of days\n",
    "    curr_day = start_date\n",
    "    while curr_day < end_date:\n",
    "        days.append(curr_day)\n",
    "        curr_day = curr_day + datetime.timedelta(days=1)\n",
    "\n",
    "    # Iterate over days and get inputs/rewards\n",
    "    for day in days:\n",
    "        daypricedata = pricedata[pricedata['DateTime'] > pd.Timestamp(day)].copy()\n",
    "        daypricedata = daypricedata[daypricedata['DateTime'] < pd.Timestamp(day) + datetime.timedelta(days=1)].copy()\n",
    "        daypricedata = daypricedata.reset_index()\n",
    "        \n",
    "        N = agent.inputs + 1\n",
    "        n = 10\n",
    "        M = len(daypricedata)-N-n\n",
    "\n",
    "        for index in range(0,M):\n",
    "            diff_price = np.diff(daypricedata['BidClose'][index:index+N])\n",
    "            normalized_vol = daypricedata['Volume'][index:index+N-1]/1000\n",
    "            ip = np.transpose(np.array((diff_price, normalized_vol)))\n",
    "            inputs.append(ip)\n",
    "            rewards.append(daypricedata['BidClose'][index+N+n] - daypricedata['BidClose'][index+N])\n",
    "            \n",
    "        \n",
    "    inputs = np.array(inputs)\n",
    "    rewards = np.array(rewards)\n",
    "    print(inputs.shape)\n",
    "    print([1, inputs.shape[0], inputs.shape[1]])\n",
    "    print(rewards.shape)\n",
    "    #inputs = inputs.reshape([1, inputs.shape[0], inputs.shape[1]])\n",
    "    \n",
    "    return (inputs, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.inputs = 3\n",
    "        self.outputs = 1\n",
    "        self.model = self.network()\n",
    "        #self.model = self.lstm_network()\n",
    "        print(self.model.summary())\n",
    "\n",
    "        \n",
    "    def lstm_network(self):\n",
    "        model = Sequential()\n",
    "        \n",
    "        num_layers = 2\n",
    "        neurons_per_layer = 20\n",
    "        dropout = 0.0\n",
    "        reg = 0.00\n",
    "        act = 'tanh'\n",
    "        output_act = 'linear'\n",
    "        learning = 0.0025\n",
    "        opt = optimizers.Adam(learning)\n",
    "        \n",
    "        lstm_out = 10\n",
    "        batch_size = 32\n",
    "\n",
    "        model = Sequential()\n",
    "        #model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2, input_shape=(100, 20, 2)))\n",
    "        model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2, input_shape=(None, 2)))\n",
    "        model.add(Dense(1,activation='softmax'))\n",
    "        model.compile(loss = 'mse', optimizer='adam')\n",
    "        \n",
    "#         for ii in range(num_layers - 1):\n",
    "#             print('garbo')\n",
    "#             model.add(LSTM(units=neurons_per_layer, activation=act,\n",
    "#                            kernel_regularizer=regularizers.l1(reg),\n",
    "#                            activity_regularizer=regularizers.l1(reg)))\n",
    "#             model.add(Dense(units=self.outputs, activation=output_act, input_dim=self.inputs,\n",
    "#                             kernel_regularizer=regularizers.l1(reg),\n",
    "#                             activity_regularizer=regularizers.l1(reg)))\n",
    "            \n",
    "#         model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "        return model\n",
    "            \n",
    "    def network(self, weights=None):\n",
    "        model = Sequential()\n",
    "        \n",
    "        num_layers = 2\n",
    "        neurons_per_layer = 20\n",
    "        dropout = 0.0\n",
    "        reg = 0.000\n",
    "        act = 'tanh'\n",
    "        output_act = 'linear'\n",
    "        learning = 0.01\n",
    "        opt = optimizers.Adam(learning)\n",
    "        \n",
    "        if num_layers == 0:\n",
    "            if dropout > 0:\n",
    "                    model.add(Dropout(dropout))\n",
    "            model.add(Dense(units=self.outputs, activation=output_act, input_dim=self.inputs,\n",
    "                        kernel_regularizer=regularizers.l2(reg),\n",
    "                        activity_regularizer=regularizers.l2(reg)))\n",
    "        else:\n",
    "            model.add(Dense(units=neurons_per_layer, activation=act, input_dim=self.inputs,\n",
    "                            kernel_regularizer=regularizers.l2(reg),\n",
    "                            activity_regularizer=regularizers.l2(reg)))\n",
    "            \n",
    "            for ii in range(num_layers - 1):\n",
    "                if dropout > 0:\n",
    "                    model.add(Dropout(dropout))\n",
    "                model.add(Dense(units=neurons_per_layer, activation=act,\n",
    "                                kernel_regularizer=regularizers.l2(reg),\n",
    "                                activity_regularizer=regularizers.l2(reg)))\n",
    "                \n",
    "            if dropout > 0:\n",
    "                    model.add(Dropout(dropout))\n",
    "            model.add(Dense(units=self.outputs, activation=output_act,\n",
    "                            kernel_regularizer=regularizers.l2(reg),\n",
    "                            activity_regularizer=regularizers.l2(reg))) \n",
    "    \n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "        return model    \n",
    "        \n",
    "    # Train the NN    \n",
    "    def train(self, inputs, outputs, epochs):\n",
    "        return self.model.fit(inputs, outputs, epochs=epochs, verbose=2, batch_size=100)\n",
    "    \n",
    "    # Train and evaluate at intervals on test data to see if the losses on test data are decreasing\n",
    "    def train_and_evaluate(self, training_inputs, training_rewards, testing_inputs, testing_rewards, epochs, epoch_eval_interval):\n",
    "        intervals = int(np.ceil(epochs/epoch_eval_interval))\n",
    "        testing_losses = []\n",
    "        testing_losses_idx = []\n",
    "        training_losses = []\n",
    "        \n",
    "        # Get the performance on the testing data before training\n",
    "        testing_losses.append(agent.model.evaluate(testing_inputs, testing_rewards))\n",
    "        testing_losses_idx.append(0)\n",
    "        \n",
    "        # Train in intervals of epochs so we can evaluate the NN performance on testing data in between\n",
    "        for ii in range(intervals):\n",
    "            history = agent.train(training_inputs, training_rewards, epochs=epoch_eval_interval)\n",
    "            interval_training_losses = history.history['loss']\n",
    "            training_losses = training_losses + interval_training_losses\n",
    "            interval_testing_loss = agent.model.evaluate(testing_inputs, testing_rewards, verbose=0)\n",
    "            testing_losses.append(interval_testing_loss)\n",
    "            testing_losses_idx.append((ii+1)*epoch_eval_interval)\n",
    "            print('At epoch ', (ii+1)*epoch_eval_interval, ' out of ', epochs)\n",
    "            print('   Mean training loss: ', round(np.mean(interval_training_losses), 5))\n",
    "            print('   Testing loss:       ', round(np.mean(interval_testing_loss), 5))\n",
    "        \n",
    "        # Convert to np.array\n",
    "        testing_losses = np.array(testing_losses)\n",
    "        testing_losses_idx = np.array(testing_losses_idx)\n",
    "        \n",
    "        return (training_losses, testing_losses, testing_losses_idx)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DQNAgent()\n",
    "\n",
    "# Indexs for training and testing ranges\n",
    "training_start_idx = 300\n",
    "training_end_idx = np.floor(len(pricedata)/2)\n",
    "testing_start_idx = training_end_idx + 1\n",
    "testing_end_idx = len(pricedata) -  1\n",
    "\n",
    "# Training date range\n",
    "training_start_date = pricedata['DateTime'][training_start_idx].date()\n",
    "training_end_date = pricedata['DateTime'][training_end_idx].date()\n",
    "\n",
    "# Testing date range\n",
    "testing_start_date = pricedata['DateTime'][testing_start_idx].date()\n",
    "testing_end_date = pricedata['DateTime'][testing_end_idx].date()\n",
    "\n",
    "# Training inputs and rewards\n",
    "(training_inputs, training_rewards) = get_inputs_and_rewards(start_date=training_start_date,\n",
    "                                                             end_date=training_end_date,\n",
    "                                                             pricedata=pricedata)\n",
    "# Testing inputs and rewards\n",
    "(testing_inputs, testing_rewards) = get_inputs_and_rewards(start_date=testing_start_date,\n",
    "                                                           end_date=testing_end_date,\n",
    "                                                           pricedata=pricedata)\n",
    "\n",
    "# # LSTM training inputs and rewards\n",
    "# (training_inputs, training_rewards) = get_lstm_inputs_and_rewards(start_date=training_start_date,\n",
    "#                                                                   end_date=training_end_date,\n",
    "#                                                                   pricedata=pricedata)\n",
    "# # LStM testing inputs and rewards\n",
    "# (testing_inputs, testing_rewards) = get_lstm_inputs_and_rewards(start_date=testing_start_date,\n",
    "#                                                                 end_date=testing_end_date,\n",
    "#                                                                 pricedata=pricedata)\n",
    "# Amount of training time\n",
    "epochs = 10000\n",
    "epoch_eval_interval = 20\n",
    "\n",
    "# Train the NN\n",
    "(training_losses, testing_losses, testing_losses_idx) = agent.train_and_evaluate(training_inputs=training_inputs,\n",
    "                                                                                 training_rewards=training_rewards,\n",
    "                                                                                 testing_inputs=testing_inputs,\n",
    "                                                                                 testing_rewards=testing_rewards,\n",
    "                                                                                 epochs=epochs,\n",
    "                                                                                 epoch_eval_interval=epoch_eval_interval)\n",
    "\n",
    "# Get the performance on the training and testing data after training\n",
    "training_predictions = agent.model.predict_on_batch(training_inputs)\n",
    "testing_predictions = agent.model.predict_on_batch(testing_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idx_plot = [ii for ii in range(len(training_predictions))]\n",
    "testing_idx_plot = [ii for ii in range(len(testing_predictions))]\n",
    "\n",
    "training_predictions_plot = [w[0] for w in training_predictions]\n",
    "testing_predictions_plot = [w[0] for w in testing_predictions]\n",
    "\n",
    "print('Mean Training Prediction: ', np.mean(training_predictions_plot))\n",
    "print('Mean Training Reward:     ', np.mean(training_rewards))\n",
    "print('Mean Testing Prediction:  ', np.mean(testing_predictions_plot))\n",
    "print('Mean Testing Reward:      ', np.mean(testing_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionsChart:\n",
    "    def __init__(self, idx, rewards, predictions, title='Plot'):\n",
    "        self.data = [\n",
    "                dict(\n",
    "                    type = 'scatter',\n",
    "                    x = idx,\n",
    "                    y = rewards,\n",
    "                    mode='lines',\n",
    "                    name='Rewards'\n",
    "                ),\n",
    "                \n",
    "                dict(\n",
    "                    type = 'scatter',\n",
    "                    x = idx,\n",
    "                    y = predictions,\n",
    "                    mode='lines',\n",
    "                    name='Predictions'\n",
    "                ),\n",
    "               ]\n",
    "        \n",
    "        self.layout = go.Layout(\n",
    "                        title=title,\n",
    "                        \n",
    "                        xaxis=dict(\n",
    "                            title='Epochs',\n",
    "                        ),\n",
    "\n",
    "                        yaxis=dict(\n",
    "                            title='Reward/Prediction',\n",
    "                        ),\n",
    "                    )\n",
    "        \n",
    "        self.chart = go.FigureWidget(data=self.data, layout=self.layout)\n",
    "        \n",
    "        self.display = self.chart\n",
    "    \n",
    "training_predictions_chart = PredictionsChart(training_idx_plot, training_rewards, training_predictions_plot, title='Training')\n",
    "training_predictions_chart.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_predictions_chart = PredictionsChart(testing_idx_plot, testing_rewards, testing_predictions_plot, title='Testing')\n",
    "testing_predictions_chart.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossesChart:\n",
    "    def __init__(self):\n",
    "        data = [\n",
    "                dict(\n",
    "                    type = 'scatter',\n",
    "                    x = [ii for ii in range(len(training_losses))],\n",
    "                    y = training_losses,\n",
    "                    mode='lines',\n",
    "                    name='Training Data Losses'\n",
    "                ),\n",
    "            \n",
    "                dict(\n",
    "                    type = 'scatter',\n",
    "                    x = testing_losses_idx,\n",
    "                    y = testing_losses,\n",
    "                    mode='lines',\n",
    "                    name='Testing Data Losses'\n",
    "                ),\n",
    "               ]\n",
    "        \n",
    "        layout = go.Layout(\n",
    "                        title = 'Losses',\n",
    "\n",
    "                        xaxis=dict(\n",
    "                            title='Epochs',\n",
    "                        ),\n",
    "\n",
    "                        yaxis=dict(\n",
    "                            title='Loss',\n",
    "                        ),\n",
    "                    )\n",
    "        \n",
    "        self.chart = go.FigureWidget( data=data, layout=layout )\n",
    "        \n",
    "        self.display = self.chart\n",
    "        \n",
    "losses_chart = LossesChart()\n",
    "losses_chart.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizedLossesChart:\n",
    "    def __init__(self):\n",
    "        data = [\n",
    "                dict(\n",
    "                    type = 'scatter',\n",
    "                    x = [ii for ii in range(len(training_losses))],\n",
    "                    y = training_losses/training_losses[0],\n",
    "                    mode='lines',\n",
    "                    name='Training Data Losses'\n",
    "                ),\n",
    "                dict(\n",
    "                    type = 'scatter',\n",
    "                    x = testing_losses_idx,\n",
    "                    y = testing_losses/testing_losses[0],\n",
    "                    mode='lines',\n",
    "                    name='Testing Data Losses'\n",
    "                ),\n",
    "               ]\n",
    "        \n",
    "        \n",
    "        layout = go.Layout(\n",
    "                        title = 'Normalized Losses',\n",
    "\n",
    "                        xaxis=dict(\n",
    "                            title='Epochs',\n",
    "                        ),\n",
    "\n",
    "                        yaxis=dict(\n",
    "                            title='Normalized Loss',\n",
    "                        ),\n",
    "                    )\n",
    "        \n",
    "        self.chart = go.FigureWidget( data=data, layout=layout )\n",
    "        \n",
    "        self.display = self.chart\n",
    "        \n",
    "normalized_losses_chart = NormalizedLossesChart()\n",
    "normalized_losses_chart.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-Do List\n",
    "\n",
    "* Extract volume per minute data from tick data\n",
    "* LossesChart/etc. applied to separate test data\n",
    "* Try feeding a vector of indicators instead of raw price data\n",
    "* Implement actual buy/sell strategy based on NN output, evaluate performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
